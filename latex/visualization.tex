\documentclass[a4paper,titlepage,12pt]{scrartcl}
\usepackage[utf8x]{inputenc}
\usepackage[paper=a4paper,includefoot,includehead,left=30mm,right=20mm,top=20mm,bottom=20mm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[ngerman]{babel}
\usepackage{ngerman}
\usepackage{thmbox}
%\usepackage{german}
%\usepackage
%[colorlinks=true,linkcolor=red,
% anchorcolor=black,citecolor=green,
% pagecolor=red,urlcolor=cyan,backref,]{hyperref}
\usepackage{cite}
\usepackage{url}
\usepackage[german]{varioref}
%Add a box around floats
\usepackage{float}
\floatstyle{boxed} 
\restylefloat{figure}

\pagestyle{headings}

\newtheorem[L]{boxedDefinition}{Definition}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\title{3D-Tumorvisualisation}
\subtitle{Seminararbeit}
\author{Uli Köhler}
%\institute[EMG]{Ernst-Mach-Gymnasium Haar}
\date{9.~November 2010}

%Utility to insert a newline after a paragraph declaration
\newcommand{\paranl}{$~~$\\}

\begin{document}
\maketitle\thispagestyle{empty}\newpage
\tableofcontents\thispagestyle{empty}\newpage
\section{Einleitung}\label{sec:introduction}
In dieser Arbeit sollen Methoden und Algorithmen diskutiert und verglichen werden, die zur dreidimensionalen Visualisation von Tumoren in Echtzeit dienen. Hierzu werden zuerst in Kapitel \vref{ssec:requirements} nach einer allgemeinen Definition dieses Begriffs die allgemeinen Anforderungen sowie in Kapitel \vref{ssec:applications} Anwendungsmöglichkeiten für solche Systeme dargestellt. Darauf aufbauend werden in Kapitel \vref{ssec:concepts} die Konzepte und Algorithmen dargestellt, die im Rahmen dieser Arbeit entwickelt wurden. Zur anschaulichen Darstellung und als Beweis für die performante Implementierbarkeit dieser Konzepte wurde begleitend zu dieser Arbeit ein Programm (`VERTEBRA`) geschrieben, anhand dessen in Kapitel \vref{ssec:implementations} verschiedene Implementationsmöglichkeiten der zuvor dargestellten Konzepte und deren Anwendbarkeit in der modernen Medizin diskutiert werden. 

Anschließend wird in Kapitel \vref{sec:augmentedreality} die Technik der `Augmented Reality` diskutiert, die in Zukunft eine wichtige Rolle in der medizinischen Visualisationstechnik, speziell im Bereich der Chirurgie spielen könnte. Zudem wird in diesem Kapitel die Anwendbarkeit der in dieser Arbeit vorgestellten Konzepte auf Augmented Reality-basierte Systeme betrachtet.
In Kapitel \vref{ssec:existingtvss} wird eine Auswahl aus bereits existierenden Systemen (einschließlich fortgeschrittenen Forschungsprojekten) zur medizinischen Visualisation betrachtet, die den Großteil der in Kapitel \ref{ssec:requirements} geforderten Bedingungen erfüllen.
Mit dem abschließenden Schlussteil, der in Kurzform die wichtigsten Thesen, Konzepte und Resultate rekapituliert, endet der Hauptteil dieser Arbeit - das Inhaltsverzeichnis der Begleit-CD sowie das Literatur- und Quellenverzeichnis,s das Abbildungsverzeichnis, eine technische Beschreibung der Plattform, auf der VERTEBRA getestet wurde sowie die obligatorische Selbstständigkeitserklärung bilden den Anhang dieses Dokuments.
\section{Echtzeit-Tumorvisualisationssysteme}\label{sec:vissystems}
\subsection{Anforderungen}\label{ssec:requirements}
Um die Anforderungen für Echtzeit-Tumorvisualisationssysteme zu erläutern, muss der Begriff zuerst mit allen zu erfüllenden Anforderungen definiert werden. Die folgende Definition basiert auf \cite[Kapitel 3.1.1., Seite 17]{Bruckner2004} sowie auf \cite{Kutter2008}
\begin{boxedDefinition}[Echtzeit-Tumorvisualisationssystem]\label{def:rttumorvissystem}
 Als Echtzeit-Tumorvisualisationssystem sei ein System definiert, das in Echtzeit in der Lage ist, aus dreidimensionalen medizinischen Eingabedatensätzen hochqualitative Ausgabedaten zu generieren, die auf visuellen Ausgabegeräten in ein Weise dargestellt werden können, die menschlichen Benutzern ermöglicht, Informationen über anatomische Strukturen zu erkennen, selbige zu unterscheiden sowie interaktiv im Datensatz zu navigieren. Der primäre Einsatzzweck des Systems besteht hierbei in der Visualisation von Tumoren, die durch spezielle Klassifizierungsverfahren visuell hervorgehoben werden.
 Ein Tumor im Sinne dieser Definition sei eine Raumforderung oder Gewebeanomalie, die sich beim verwendeten Verfahren, die medizinischen Eingabedaten zu gewinnen, vom umgebenden Gewebe oder Raum abzeichnet.
\end{boxedDefinition}

\noindent Im Einzelnen sind die Anforderungen wie folgt zu beschreiben:
\paragraph{Echtzeitfähigkeit und Interaktionsfähigkeit} \label{p:rtcapability} Das System muss in der Lage sein, Eingabedaten in Echtzeit zu verarbeiten, sodass der menschliche Benutzer eine Änderung der Ausgabedaten nicht als Einzelbildsequenz sondern als dynamischen Prozess wahrnimmt (vgl \cite[Kapitel 1, Seite 1]{Moeller2008}). Eine Vergleichsgrösse ist die Einheit FPS, die die Anzahl der Bilder pro Sekunde angibt. Möller et al. definieren in \cite{Moeller2008}, dass ab 6 FPS für das menschliche Auge der Übergang von Einzelbildern zu einer Bewegung zunimmt und ab 15 FPS ein Programm als sicher echtzeitfähig gelten kann - ab 72 FPS kann das menschliche Auge keinen Unterschied mehr entdecken (vgl. \cite[Kapitel 1, Seite 1]{Moeller2008}). Als weiteres Kriterium führen Möller et al. an, dass ein derartiges System fähig sein muss, auf Benutzerinteraktionen mit geringer Latenzzeit zu reagieren (vgl. \cite[Kapitel 1, Seite 1]{Moeller2008}).

\paragraph{Medizinische 3D-Eingabedaten} Ein Echtzeit-Tumorvisualisationssystem dient in Sinne der obigen Definition zur Verarbeitung medizinischer Eingabedaten. Die Eingabedaten müssen sich über drei Dimensionen erstrecken. CT- und MRT-Scanner liefern mehrere zweidimensionale Datensätze, die zusammengenommen einen dreidimensionalen Eingabedatensatz bilden. Obwohl in der Praxis nicht üblich kann auch ein einzelner zweidimensionaler Datensatz als dreidimensionaler Eingabedatensatz mit der Tiefe 1 gelten. Systeme. Von den Eingabedaten wird nicht gefordert, dass sie konstant bleiben - dadurch wird der Einsatz des Systems in intraoperativen Verfahren mit wiederholten tomografischen Scans wie dem in \cite{Okudera1994}, das den Einsatz eines solchen Verfahrens bei der chirurgischen Entfernung von Gliazellemtumoren examplarisch beschreibt, ermöglicht. Um die Eingabedaten für die Software lesbar zu machen, müssen die Datensätze entweder in einem speziellen Format wie dem DICOM-Standard gespeichert werden, zu dem \cite{Mildenberger2002} eine Einführung bietet, oder aber es findet eine direkte Anbindung an die Scannerhardware statt.

\paragraph{Hochqualitative Ausgabedaten} Das System muss in der Lage sein, die Daten in einer Art und Weise zu visualisieren, die eine für die Anwendung und das verwendete visuelle Ausgabegerät angemessene Qualität liefert - da hochqualitative Rendertechniken eine höhere Rechenleistung erfordern, muss dafür die Bildrate reduziert werden. Da ab einer bestimmten Qualitätsstufe die subjektiv wahrgenommene Qualität nicht mehr steiht, macht es keinen Sinn, die Qualität ab dieser Stufe weiter auf Kosten der Bildrate zu steigern (vgl. \cite[Kapitel 3.3, Seite 5]{Kutter2008}).

\paragraph{Klassifizierungsverfahren für Tumoren} Vom System wird gefordert, Klassifizierungsalgorithmen\footnote{Klassifizierung - Prozess, um einem einzelnen Datenelement eine Farbe und Transparenz zuzuordnen (vgl. \cite[Kapitel 3.2.2, Seite 28]{Bruckner2004})}\textsuperscript{,}\footnote{Anmerkung: Die hier behandelte Klassifizierung ist nicht mit der taxonomischen Klassifikation von Tumoren zu verwechseln} ausführen zu können, die zur visuellen 

\paragraph{Vergleich zu \cite[Kapitel 3.1.1, Seite 17f.]{Bruckner2004}}\paranl
Anmerkung: Diese Definition unterscheidet sich von den in \cite[Kapitel 3.1.1, Seite 17]{Bruckner2004} beschriebenen Anforderungen durch die Spezialisierung auf Tumoren, die explizit geforderte Echtzeitfähigkeit sowie die nicht vorhandene Anforderung, das System in reiner Software zu implementieren (siehe dazu auch Kapitel \vref{ssec:swhwcomparison}). Die obige Definition ist zudem im Bezug auf das eingesetzte Verfahren zur Gewinnung der Eingabedaten allgemein gehalten, während \cite{Bruckner2004} sich primär auf CTs und MRTs konzentriert.

\subsection{Anwendungsmöglichkeiten}\label{ssec:applications}
Schon heute werden verschiedene medizinische Visualisationssysteme in den verschiedensten Bereichen der Medizin eingesetzt.
\section{Konzepte zur Tumorklassifizierung}\label{ssec:concepts}
\begin{figure}[p]
\begin{center}
\includegraphics[width=\textwidth]{graphics/Classification.pdf}
\caption{Verarbeitung von CT-Eingabedaten in VERTEBRA}
\label{gradientmapping-graphic}
\end{center}
\end{figure}
\subsection{Implementationsmöglichkeiten am Beispiel des Projektes VERTEBRA}\label{ssec:implementations}
Als Begleitprojekt zu dieser Arbeit wurde das Programm VERTEBRA (Volumetric Examiner for Radiological and Tomographical Experimental Basic Realtime Analysis) geschrieben, dessen Hauptzweck darin besteht, die Machbarkeit in dieser Arbeit vorgestellten Konzepte zu demonstrieren und im Rahmen der erreichbaren Genauigkeit vergleichbare Daten über die Echtzeittauglichkeit der Algorithmen und Verfahren zu liefern.

VERTEBRA ist ein Proof-of-Concept-Projekt, zielt also nicht darauf ab, ein im medizinischen Alltag einsetzbares Produkt zu sein oder die für eine Zulassung nach dem Medizinproduktegesetz (bezogen auf deutsches Recht) notwendigen Vorraussetzungen zu schaffen.
\subsection{Grenzen der vorgestellten Konzepte}\label{ssec:limits}
\paragraph{Abhängigkeit von den Eingabedaten}
Die in dieser Arbeit vorgestellten Verfahren benutzen mathematische Verfahren, um eine Eingabedatenmenge variabler Größe in eine Menge an Eingabedaten zu übersetzen, die von spezialisierter Grafikhardware mathematisch in ein zweidimensionales Ausgangsbild umgerechnet wird, um auf einem visuellen Ausgabegerät, zum Beispiel einem Monitor angezeigt zu werden. Aufgrund dieser mathematischen Umrechnung basieren die Ausgabedatenmengen dieser Algorithmen ausschließlich auf den Eingabedatenmengen, die üblicherweise Datensätze aus tomografischen Scannern repräsentieren und den Konfigurationsparametern der Algorithmen.
\subsection{Methoden zur Berechnung von Visualisationsdaten}
\subsubsection{Vergleich von Software- und Hardwarealgorithmen}\label{ssec:swhwcomparison}

\subsubsection{Berechnung auf dem Hauptprozessor}\label{sssec:cpucalculation}
Die naheliegendste Möglichkeit, Operationen auf großen Mengen volumetrischen Daten durchzuführen, ist, die Berechnungen vom Hauptprozessor des Computers durchführen zu lassen. 
\subsubsection{Berechnung auf GPUs}\label{sssec:gpucalculation}
Da die Rechenleistung der Hauptprozessoren moderner Computer für viele der heutigen 3D-Anwendungen nicht mehr ausreicht, enthält ein Großteil der heutigen Computer Grafikhardware, die in der Lage ist, 3D-Anwendungen zu beschleunigen. Hierbei berechnet der Hauptprozessor die darzustellenden Daten und gibt sie an die Grafikhardware weiter, die diese Daten mithilfe der GPU\footnote{GPU - Graphics Processing Unit - Grafikprozessor} in ein zweidimensionales Bild umwandelt (rendert), das beispielsweise auf einem Monitor angezeigt werden kann.

Um der GPU mitzuteilen, welche Objekte wo im dreidimensionalen Koordinatensystem auf welche Art gerendert werden sollen, müssen Programme ein Grafik-API\footnote{API - Application Programming Interface - Programmierschnittstelle} wie OpenGL oder DirectX benutzen. Im konkreten Fall von VERTEBRA fiel die Entscheidung aufgrund der Plattformunabhängigkeit auf OpenGL.

\marginpar{Shader}
Neuere GPUs können ausserdem so genannte Shader ausführen - kleine Programme, die für bestimmte Untereinheiten der zu visualisierenden Objekte ausgeführt werden. OpenGL stellt hierfür die Shaderprogrammiersprache GLSL\footnote{GLSL - [Open]Graphics Layer Shading Language - OpenGL-Shadersprache} zur Verfügung, die in \cite{Rost2006} für die OpenGL-Version 2.0 ausführlich beschrieben wird. Nach \cite[Seite 38-47]{Rost2006} können in dieser Sprachversion die folgenden Typen von Shadern unterschieden werden\footnote{Geometry-Shader sind im in \cite{Rost2006} benutzten Standard OpenGL 2.0 nicht enthalten und werden daher an dieser Stelle nicht aufgeführt}:
\begin{itemize}
 \item Vertex\footnote{Vertex - Ein einzelner Punkt im Raum, der einen Eckpunkt eines Polygons bzw. einen Punkt oder eines der Enden einer Linie darstellt. - Vgl. \cite[Seite 664]{Wright2000} bzw. \cite[Seite 685]{Rost2006}}-Shader
 \item Fragment\footnote{Fragment - Datensatz bestehend aus der Information, die nötig ist, um ein Pixel zu zeichnen\\Vgl. \cite[Seite 675]{Rost2006}}-Shader
\end{itemize}
Die Shader-Prozessoren (Untereinheiten der GPU, die die Shader ausführen), arbeiten massiv parallel, führen also das Shaderprogamm für eine große Zahl an Vertices bzw. Fragments gleichzeitig aus. Dies wird durch die spezielle Hardwarearchitektur von GPUs ermöglicht. Daraus resultiert ein großer Zuwachs an Geschwindigkeit, was speziell für Echtzeit-Tumorvisualisationssysteme wichtig ist, da die Operationen ständig über neuen Datensätzen berechnet werden müssen. Das in \vref{ssec:requirements} dargestellte Echzeitkriterium wäre nicht erfüllt, falls die Zeit, die benötigt wird, um die Berechnungen einschließlich Rendering auf einem Datensatz auszuführen, größer ist als die Zeitdifferenz zum Eintreffen des nächsten Datensatzes. Durch die massive Parallelisierung kann dieses Kriterium somit für größere Datensätze erfüllt werden.
Den Ansatz, Fragment-Shader für GPU-beschleunigtes Volumenrendering zu benutzen, verfolgen unter anderem Kruger und Westermann in \cite{Kruger2003}.

In den letzten Jahren tritt abgesehen von den Shadern vor allem das GPGPU\footnote{GPGPU - General Purpose Graphics Processing Unit}-Konzept in den Vordergrund, das die Möglichkeit bereitstellt, GPUs frei programmieren zu können, im Gegensatz zu Shadern aber nicht auf Grafikdatenmengen wie Vertices oder Framente sondern auf beliebigen Eingabedatensätzen ausgeführt wird. Wie auch bei Shadern kann die Anwendung von der massiven Parallelisierung profitieren. Auch für GPGPU-Programmierung müssen bestimmte APIs definiert werden, um der Applikation den nötigen Zugriff auf die Grafikhardware zu gewähren - \cite{Sanders2010} führt in das CUDA\footnote{CUDA - Compute Unified Device Architecture}-API des GPU-Herstellers NVIDIA ein, während \cite{Kirk2010} neben CUDA das herstellerunabhängige OpenCL\footnote{OpenCL - Open Computing Language} thematisiert. Marsalek et al. wenden schließlich das GPGPU-Konzept auf das Volumenrendering an und stellen ihre CUDA-basierte Implementation in \cite{Marsalek2008} vor.
\subsubsection{Berechnung auf FPGAs}
Abgesehen von den bereits diskutierten Möglichkeiten ist mit so genannten FPGAs\footnote{FPGA - Field Programmable Gate Array} eine weitere Form der Hardwarebeschleunigung für die medizinische Visualisationstechnik vorhanden. FPGAs sind ICs\footnote{IC - Integrated Circuit - Integrierter Schaltkreis}, bei denen nach der Herstellung eine anwendungsspezifische Programmierung und Konfiguration möglich ist (\cite{Kibritev2009}, Kapitel 1.7.1, Seite 16). Daher sind die Produktionskosten für ein auf FPGAs basierendes Visualisationssystem wesentlich geringer als bei dedizierter Hardware, die für eine bestimmte Aufgabe gefertigt wurde und nicht nachträglich programmierbar ist. Wie bereits in Kapitel \vref{ssec:swhwcomparison} diskutiert stellt Bruckner in \cite{Bruckner2004} Nachteile von hardwarebasiertem Rendering gegenüber softwarebasierten Darstellungen in Bezug auf große volumetrische Datensätze dar. FPGAs erlauben, wie Leeser et al. in \cite{Leeser2005} mithilfe einer Implementation des Parallel-Beam Backprojection-Algorithmus zeigen, eine performante Implementation dieser Softwarealgorithmen. In \cite{Thomas2009} findet sich ein Vergleich die Performanz von CPU-, GPU- und FPGA-basierten Systemen anhand von PRNGs\footnote{PRNG - Pseudo-random number generator - Pseudozufallszahlengenerator} - wie aus Tabelle 6 ersichlich liefert das im Experiment benutzt FPGA-basierte System bei zwei der drei dargestellen Verteilungen, die jeweils unterschiedliche Algorithmen benötigen bessere Resultate (also eine größere Zahl generierter Zufallszahlen pro Zeiteinheit) als die anderen getesteten Plattformen.
\subsubsection{Berechnung auf Spezialhardware}
Neben den dargestellten Visualisationsmethoden gibt es durchaus Ansätze, die für die Visualisation nötigen Berechnungen auf spezialisierter Hardware auszuführen. Aufgrund des geringen Umfangs dieser Arbeit soll an dieser Stelle lediglich ein Überblick über die bereits bestehenden Hardwareplattformen gegeben werden. Diese Zusammenstellung basiert auf \cite[Kapitel 2.5.5, Seite 14]{Bruckner2004}.
\begin{itemize}
 \item Günter Knittel beschreibt in \cite{Knittel1995} mit VOGUE eine skalierbare Architektur für Volumenrendering
 \item VIRIM ist eine massiv-parallele, echtzeitfähige Volumenrenderingarchitektur, die in \cite{Guenther1995} beschrieben wird
 \item In \cite{Meissner2002} beschreiben Meißner et al. VIZARD II, eine interaktive und rekonfigurierbare Volumenrenderingarchitektur
 \item Eine kostenoptimierte, echtzeitfähige Architektur namens EM-Cube beschreiben Osborne et al. in \cite{Osborne1997}
 \item EM-Cube dient zudem als Basis für das kommerziell verfügbare VolumePro board, das in \cite{Pfister1999} beschrieben wird (vgl. \cite[Kapitel 2.2.5, Seite 14]{Bruckner2004})
\end{itemize}
Insbesondere bei \cite{Knittel1995}, \cite{Guenther1995} sowie \cite{Osborne1997} ist zu beachten, dass das Publikationsdatum sehr lange zurückliegt und daher unter Umständen nicht ausreichend mit aktueller Hardware zusammenarbeiten - beispielsweise könnte die Auflösung und Geschwindigkeit der heutigen Tomographen für die echtzeitfähigen Systeme ein Problem darstellen. Das kommerziell verfügbare VolumePro-Board aus \cite{Pfister1999} ist jedoch laut \cite[Kapitel 2.2.5, Seite 14]{Bruckner2004} fähig, einen Datensatz mit einer Auflösung von 512 in allen drei Raumdimensionen mit einer Geschwindigkeit von 30 FPS\footnote{FPS - Frames per second - Bilder pro Sekunde} zu rendern.
\subsubsection{Surface Rendering}
Die in dieser Arbeit behandelten Methoden beschränken sich auf das Volume Rendering (`Volumenrendern`), d.h. die Daten werden unter Beachtung der räumlichen Information gerendert. Als Alternative bietet sich das so genannte Surface Rendering (`Oberflächenrendern`) an, bei dem durch mathematische Verfahren Oberflächen im Datensatz gesucht werden, die dann als zusammenhängende Fläche gerendert werden. 

Kuszyk et al. stellen in \cite{Kuszyk1996} die Nachteile des Surface Renderings gegenüber dem Volume Rendering dar. Als Beispiel für einen Nachteil des Surface Rendering wird dargestellt, dass Läsionen unter Knochen verborgen werden während Volume Rendering-Algorithmen diese korrekt darstellen (Quelle: \cite{Kuszyk1996}, Abstract). Da die Publikation jedoch schon 1996 veröffentlicht wurde, gelten die Resultate unter Umständen für die heutigen Algorithmen und hochauflösenden Tomographen. Eine aktuellere Darstellung liefern Udupa et al. in \cite{Udupa2009}. Die Autoren kommen zu dem Schluss, dass Surface Rendering-Algorithmen im Bereich der Informationsdarstellung einen kleinen Vorteil gegenüber volumenbasierten Algorithmen haben und außerdem durch den geringeren Bedarf an Rechenzeit und Speicherplatz überlegen sind. Auch \cite{Bruckner2004} thematisiert den Vergleich von Oberflächen- und Volumenrendering, kommt aber im Gegensatz zur vorgenannten Publikation zum Schluss, dass der Mehraufwand an Rechenzeit und Speicher die Mehrinformation wert, die im gerenderten Bild angezeigt wird - tatsächlich würde beim Rendern der Oberflächen eine Dimension verloren gehen, da das Innere von Objekten verborgen bleibt (Quelle: \cite[Seite 2f.]{Bruckner2004}).

\section{Augmented Reality - Zukunft von Visualisationssystemen?}\label{sec:augmentedreality}
In den letzten Jahren wird neben den herkömmlichen Geräten zu Darstellung der Informationen medizinischer Informationssysteme (z.B. Bildschirme) intensiv an der so genannten `Augmented Reality` geforscht. Dieser Begriff, der sich mit 'Erweiterte Realität' (Quelle: \cite[Seite 1]{Toe2010}) übersetzen lässt, beschreibt laut \cite{Suthau2002DE} (Seite 1; Englische Publikation: \cite{Suthau2002}) das Konzept, reale Bilder mit zusätzlichen Informationen zu ergänzen.

\section{Existierende Visualisationssysteme} \label{ssec:existingtvss}

\appendix \label{appendixstart}
\section{Anleitung zur Übersetzung von VERTEBRA}
Um den Quellcode von VERTEBRA in Maschinencode zu übersetzen, werden die folgenden Hilfsprogramme bzw. Bibliotheken benötigt:
\begin{itemize}
 \item C++-Compiler kompatibel zu ISO/IEC C++ 2003
 \item Qt Software Development Toolkit (SDK): minimal Version 4.7.0 = Qt SDK 2009.05.1
 \item DCMTK 3.5.4
\end{itemize}

Das Qt SDK kann von \url{http://qt.nokia.com} bezogen werden; die DCMTK-Bibliothek, die zum einlesen von DICOM-Daten benutzt wird, wird vom OFFIS e.v. (Oldenburger Forschungs- und Entwicklungsinstitut für Informatik, \url{http://offis.de}) auf \url{http://www.dcmtk.org/dcmtk.php.de} zu Verfügung gestellt.

Das Programm wurde mit der folgenden Konfiguration erfolgreich getestet (siehe auch Kapitel \vref{apdx:testplatform}):
\begin{itemize}
 \item C++-Compiler: GNU Compiler Collection \textit{gcc (Ubuntu/Linaro 4.4.4-14ubuntu5) 4.4.5}
 \item Qt SDK: 4.7.0 = Qt SDK 2009.05.1
\end{itemize}

\section{Testplattform}\label{apdx:testplatform}
Die in dieser Arbeit vorgestellten Geschwindigkeitsmessungen wurden auf der folgenden Plattform durchgeführt:
\begin{itemize}
  \item Dell Inspiron 530
  \item CPU: Intel\textsuperscript{\textregistered} Core\texttrademark 2 Duo E8300; 2.83GHz Taktfrequenz
  \item Betriebssystem: KUbuntu 10.10 x86\_64; Kernel 2.6.35-22-generic x86\_64
  \item Grafikhardware: NVidia\textsuperscript{\textregistered} GeForce 9400 GT, PCI Express x16\\
	Treiber 260.19.06 (Konfiguration: High Performance)
\end{itemize}
\newpage
%\nocite{*}
\renewcommand\refname{Literatur- und Quellenverzeichnis}
\bibliographystyle{plaindin}
\bibliography{visualization}
\clearpage
\section{Selbstständigkeitserklärung}
Hiermit erkläre ich, dass ich die vorliegende Arbeit in allen Teilen selbstständig verfasst habe und keine anderen als die angegebenen Quellen und Hilfsmittel (einschließlich Onlinequellen und elektronischer Medien) benutzt habe.
\vfill
\begin{center}
\underline{\hspace{10cm}}\vspace{1cm}
\end{center}
\begin{center}
Uli Köhler
\end{center}
\vfill
\end{document}
\label{ssec:existingtvss}
