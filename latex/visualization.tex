\documentclass[a4paper,titlepage,12pt]{scrartcl}
\usepackage[utf8x]{inputenc}
\usepackage[paper=a4paper,includefoot,includehead,left=30mm,right=20mm,top=20mm,bottom=20mm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage[ngerman]{babel}
\usepackage{thmbox}
%\usepackage{german}
%\usepackage
%[colorlinks=true,linkcolor=red,
% anchorcolor=black,citecolor=green,
% pagecolor=red,urlcolor=cyan,backref,]{hyperref}
\usepackage{cite}
\usepackage{url}
\usepackage[german]{varioref}
%Add a box around floats
\usepackage{float}
\floatstyle{boxed} 
\restylefloat{figure}

\pagestyle{headings}

\newtheorem[L]{boxedDefinition}{Definition}

\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\title{3D-Tumorvisualisation}
\subtitle{Seminararbeit}
\author{Uli Köhler}
%\institute[EMG]{Ernst-Mach-Gymnasium Haar}
\date{9.~November 2010}

\newcommand{\footnoteremember}[2]{
  \footnote{#2}
  \newcounter{#1}
  \setcounter{#1}{\value{footnote}}
}
\newcommand{\footnoterecall}[1]{
  \footnotemark[\value{#1}]
}

%Utility to insert a newline after a paragraph declaration
\newcommand{\paranl}{$~~$\\}

\begin{document}
\maketitle\thispagestyle{empty}\newpage
\tableofcontents\thispagestyle{empty}\newpage
\section{Einleitung}\label{sec:introduction}
In dieser Arbeit sollen Methoden und Algorithmen diskutiert und verglichen werden, die zur dreidimensionalen Visualisation von Tumoren in Echtzeit dienen. Hierzu werden zuerst in Kapitel \vref{ssec:requirements} nach einer allgemeinen Definition dieses Begriffs die allgemeinen Anforderungen sowie in Kapitel \vref{ssec:applications} Anwendungsmöglichkeiten für solche Systeme dargestellt. Darauf aufbauend werden in Kapitel \vref{ssec:concepts} die Konzepte und Algorithmen dargestellt, die im Rahmen dieser Arbeit entwickelt wurden. Zur anschaulichen Darstellung und als Beweis für die performante Implementierbarkeit dieser Konzepte wurde begleitend zu dieser Arbeit ein Programm (\glqq VERTEBRA\grqq) geschrieben, anhand dessen in Kapitel \vref{ssec:implementations} verschiedene Implementationsmöglichkeiten der zuvor dargestellten Konzepte und deren Anwendbarkeit in der modernen Medizin diskutiert werden. 

Anschließend wird in Kapitel \vref{sec:augmentedreality} die Technik der `Augmented Reality` diskutiert, die in Zukunft eine wichtige Rolle in der medizinischen Visualisationstechnik, speziell im Bereich der Chirurgie spielen könnte. Zudem wird in diesem Kapitel die Anwendbarkeit der in dieser Arbeit vorgestellten Konzepte auf Augmented Reality-basierte Systeme betrachtet.
In Kapitel \vref{ssec:existingtvss} wird eine Auswahl aus bereits existierenden Systemen (einschließlich fortgeschrittenen Forschungsprojekten) zur medizinischen Visualisation betrachtet, die den Großteil der in Kapitel \ref{ssec:requirements} geforderten Bedingungen erfüllen.
Mit dem abschließenden Schlussteil, der in Kurzform die wichtigsten Thesen, Konzepte und Resultate rekapituliert, endet der Hauptteil dieser Arbeit.
\section{Echtzeit-Tumorvisualisationssysteme}\label{sec:vissystems}
\subsection{Anforderungen}\label{ssec:requirements}
Um die Anforderungen für Echtzeit-Tumorvisualisationssysteme zu erläutern, muss der Begriff zuerst mit allen zu erfüllenden Anforderungen definiert werden. Die folgende Definition basiert auf \cite[Kapitel 3.1.1., Seite 17]{Bruckner2004} sowie auf \cite{Kutter2008}
\begin{boxedDefinition}[Echtzeit-Tumorvisualisationssystem]\label{def:rttumorvissystem}
 Als Echtzeit-Tumorvisualisationssystem sei ein System definiert, das in Echtzeit in der Lage ist, aus dreidimensionalen medizinischen Eingabedatensätzen hochqualitative Ausgabedaten zu generieren, die auf visuellen Ausgabegeräten in ein Weise dargestellt werden können, die menschlichen Benutzern ermöglicht, Informationen über anatomische Strukturen zu erkennen, selbige zu unterscheiden sowie interaktiv im Datensatz zu navigieren. Der primäre Einsatzzweck des Systems besteht hierbei in der Visualisation von Tumoren, die durch spezielle Klassifizierungsverfahren visuell hervorgehoben werden.
 Ein Tumor im Sinne dieser Definition sei eine Raumforderung oder Gewebeanomalie, die sich beim verwendeten Verfahren, die medizinischen Eingabedaten zu gewinnen, vom umgebenden Gewebe oder Raum abzeichnet.
\end{boxedDefinition}
\newpage
\noindent Im Einzelnen sind die Anforderungen wie folgt zu beschreiben:
\paragraph{Echtzeitfähigkeit und Interaktionsfähigkeit} \label{p:rtcapability} Das System muss in der Lage sein, Eingabedaten in Echtzeit zu verarbeiten, sodass der menschliche Benutzer eine Änderung der Ausgabedaten nicht als Einzelbildsequenz sondern als dynamischen Prozess wahrnimmt (vgl \cite[Kapitel 1, Seite 1]{Moeller2008}). Eine Vergleichsgrösse ist die Einheit FPS, die die Anzahl der Bilder pro Sekunde angibt. Möller et al. definieren in \cite{Moeller2008}, dass ab 6 FPS für das menschliche Auge der Übergang von Einzelbildern zu einer Bewegung zunimmt und ab 15 FPS ein Programm als sicher echtzeitfähig gelten kann - ab 72 FPS kann das menschliche Auge keinen Unterschied mehr entdecken (vgl. \cite[Kapitel 1, Seite 1]{Moeller2008}). Als weiteres Kriterium führen Möller et al. an, dass ein derartiges System fähig sein muss, auf Benutzerinteraktionen mit geringer Latenzzeit zu reagieren (vgl. \cite[Kapitel 1, Seite 1]{Moeller2008}).

\paragraph{Medizinische 3D-Eingabedaten} Ein Echtzeit-Tumorvisualisationssystem dient in Sinne der obigen Definition zur Verarbeitung medizinischer Eingabedaten. Die Eingabedaten müssen sich über drei Dimensionen erstrecken. CT- und MRT-Scanner liefern mehrere zweidimensionale Datensätze, die zusammengenommen einen dreidimensionalen Eingabedatensatz bilden. Obwohl in der Praxis nicht üblich kann auch ein einzelner zweidimensionaler Datensatz als dreidimensionaler Eingabedatensatz mit der Tiefe 1 gelten. Systeme. Von den Eingabedaten wird nicht gefordert, dass sie konstant bleiben - dadurch wird der Einsatz des Systems in intraoperativen Verfahren mit wiederholten tomografischen Scans wie dem in \cite{Okudera1994}, das den Einsatz eines solchen Verfahrens bei der chirurgischen Entfernung von Gliazellemtumoren examplarisch beschreibt, ermöglicht. Um die Eingabedaten für die Software lesbar zu machen, müssen die Datensätze entweder in einem speziellen Format wie dem DICOM-Standard gespeichert werden, zu dem \cite{Mildenberger2002} eine Einführung bietet, oder aber es findet eine direkte Anbindung an die Scannerhardware statt.

\paragraph{Hochqualitative Ausgabedaten} Das System muss in der Lage sein, die Daten in einer Art und Weise zu visualisieren, die eine für die Anwendung und das verwendete visuelle Ausgabegerät angemessene Qualität liefert - da hochqualitative Rendertechniken eine höhere Rechenleistung erfordern, muss dafür die Bildrate reduziert werden. Da ab einer bestimmten Qualitätsstufe die subjektiv wahrgenommene Qualität nicht mehr steiht, macht es keinen Sinn, die Qualität ab dieser Stufe weiter auf Kosten der Bildrate zu steigern (vgl. \cite[Kapitel 3.3, Seite 5]{Kutter2008}).

\paragraph{Klassifizierungsverfahren für Tumoren}Vom System wird gefordert, Klassifizierungsalgorithmen\footnote{Klassifizierung - Prozess, um einem einzelnen Datenelement eine Farbe und Transparenz zuzuordnen (vgl. \cite[Kapitel 3.2.2, Seite 28]{Bruckner2004})}\textsuperscript{,}\footnote{Anmerkung: Die hier behandelte Klassifizierung ist nicht mit der taxonomischen Klassifikation von Tumoren zu verwechseln} ausführen zu können, die zur visuellen 

\paragraph{Vergleich zu \cite[Kapitel 3.1.1, Seite 17f.]{Bruckner2004}}\paranl\label{p:bru04comparison}
Anmerkung: Diese Definition unterscheidet sich von den in \cite[Kapitel 3.1.1, Seite 17]{Bruckner2004} beschriebenen Anforderungen durch die Spezialisierung auf Tumoren, die explizit geforderte Echtzeitfähigkeit sowie die nicht vorhandene Anforderung, das System in reiner Software zu implementieren (siehe dazu auch Kapitel \vref{ssec:swhwcomparison}). Die obige Definition ist zudem im Bezug auf das eingesetzte Verfahren zur Gewinnung der Eingabedaten allgemein gehalten, während \cite{Bruckner2004} sich primär auf CTs und MRTs konzentriert.

\subsection{Anwendungsmöglichkeiten}\label{ssec:applications}
Schon heute werden verschiedene medizinische Visualisationssysteme in den verschiedensten Bereichen der Medizin eingesetzt.
\section{Konzepte zur Tumorvisualisation}\label{ssec:concepts}
\subsection{Algorithmen zur Klassifizierung}
\begin{figure}[p]
\begin{center}
\includegraphics[width=\textwidth]{graphics/Classification.pdf}
\caption{Verarbeitung von CT-Eingabedaten in VERTEBRA}
\label{gradientmapping-graphic}
\end{center}
\end{figure}ssec:implementations
\subsection{Implementationsmöglichkeiten am Beispiel des Projektes VERTEBRA}\label{ssec:implementations}
Als Begleitprojekt zu dieser Arbeit wurde das Programm VERTEBRA (Volumetric Examiner for Radiological and Tomographical Experimental Basic Realtime Analysis) geschrieben, dessen Hauptzweck darin besteht, die Machbarkeit in dieser Arbeit vorgestellten Konzepte zu demonstrieren und im Rahmen der erreichbaren Genauigkeit vergleichbare Daten über die Echtzeittauglichkeit der Algorithmen und Verfahren zu liefern.

VERTEBRA ist ein Proof-of-Concept-Projekt, zielt also nicht darauf ab, ein im medizinischen Alltag einsetzbares Produkt zu sein oder die für eine Zulassung nach dem Medizinproduktegesetz (bezogen auf deutsches Recht) notwendigen Vorraussetzungen zu schaffen.
\subsection{Grenzen der vorgestellten Konzepte}\label{ssec:limits}
\paragraph{Abhängigkeit von den Eingabedaten}
Die in dieser Arbeit vorgestellten Verfahren benutzen algorithmische Verfahren, um den medizinischen Eingabedatensatz in einen visualisierbaren Ausgabedatensatz umzurechnen (siehe Kapitel \ref{ssec:requirements}). Daher hängt die Qualität der Ausgabedaten direkt von der Qualität der Eingabedaten ab. Da die Daten üblicher
\subsection{Methoden zur performanten Berechnung von Visualisationsdaten}
\subsubsection{Vergleich von Hardware- und Softwarealgorithmen}\label{ssec:swhwcomparison}
Grundsätzlich lassen sich zwei Methoden zur Umwandlung der Eingabedaten in Ausgabedaten unterscheiden\footnote{Anmerkung: Hierzu zählen nicht die visuellen Ausgabegeräte, die mitunter von System zu System variieren}:
\begin{itemize}
 \item \textbf{Hardwarealgorithmen}: Diese Methode benutzt für einen oder mehrere Berechnungsschritte Hardware, deren Vorhandensein nicht auf allen Plattformen garantiert ist.\footnote{Anmerkung: Im Sinne dieser Definition gelten CPUs nicht als Spezialhardware, da sie notwendigerweise zur Datenverarbeitung auf Systemen, auf denen die hier beschriebenen Algorithmen lauffähig  wären, vorhanden sein müssen.}\textsuperscript{,}\footnote{Anmerkung: Diese Hardware ist nicht zwangsläufig mit der in Kapitel \ref{sssec:specialhardwarecalculation} beschriebenen Spezialhardware gleichzusetzen}\\
 Beispiele für Hardware im Sinne dieser Definition beschrieben, sind:
 \begin{itemize}
  \item GPUs, siehe Kapitel \vref{sssec:gpucalculation} 
  \item FPGAs, siehe Kapitel \vref{sssec:fpgacalculation}
  \item Spezialhardware, siehe Kapitel \vref{sssec:specialhardwarecalculation}
 \end{itemize}
 \item \textbf{Softwarealgorithmen}: Diese Methode benutzt für keinen Berechnungsschritt derartige Hardware.
\end{itemize}

Bruckner vergleicht in \cite{Bru08} diese Methoden wie folgt:\\
Obwohl Grafikhardware genutzt werden könnte, um die Geschwindigkeit eines Volumenrenderingsystems zu erhöhen, entstehen dadurch Probleme wie veraltete Treiber\footnote{Anmerkung: Ein Treiberupdate würde eine erneute Zertifizierung nach dem Medizinproduktegesetz erfordern und wäre daher kosten- und zeitintensiv} oder der Unterschied von unterstützten Funktionen von System zu System (übersetzt aus \cite[Kapitel 3.1.1, Seite 17, Paragraph \glqq Pure Software \grqq]{Bruckner2004}).
Bruckner stellt daher an die in seiner Arbeit verwendeten Verfahren den Anspruch, in reiner Software implementiert zu sein, also Softwarealgorithmen im Sinne der obigen Definition zu sein. Diese Arbeit behandelt dagegen auch Hardwarealgorithmen, da der Performancegewinn mitunter nicht unerheblich ist und aktive Forschung über beide Methoden betrieben wird (für Publikationen über Hardwarealgorithmen siehe auch Kapitel \ref{sssec:gpucalculation} sowie Kapitel \ref{sssec:fpgacalculation}).

\subsubsection{Berechnung auf dem Hauptprozessor}\label{sssec:cpucalculation}
Die naheliegendste Möglichkeit, Operationen auf großen Mengen volumetrischen Daten durchzuführen, ist, die Berechnungen vom Hauptprozessor des Computers durchführen zu lassen. Da diese Recheneinheit auf allen heute üblichen Computerplattformen vorhanden ist, bleibt die Applikation unabhängig von spezieller Hardware.

Obwohl moderne Prozessoren mehrere Rechenkerne besitzen und dadurch eine Parallelisierung möglich ist, bietet denoch spezialisierte Hardware eine höhere Parallelisierbarkeit. Zudem muss zur Optimierung der Geschwindigkeit einer Applikation oft der Code auf bestimmte CPUs bzw. CPUs eines bestimmten Herstellers optimiert werden. Beispielsweise unterstützen moderne Prozessoren so genannte SIMD\footnote{SIMD - Single Instruction Multiple Data}-Operationen, die dem Programm erlauben, eine Operation (vor allem arithmetische) auf mehrere Variablen gleicher Länge und gleichen Typs auf einmal anzuwenden (vgl. \cite[Kapitel 12, Seite 103]{Fog2010}. Sofern eine Applikation solche Befehle benutzt\footnote{Anmerkung: Für C/C++ bieten die so genannten Intrinsics ein API zur Benutzung dieser Operationen, siehe auch [Kapitel 12.3, Seite 107]{Fog2010}}, entsteht dadurch eine Abhängigkeit von Plattformen, die Prozessoren verbaut haben, die die jeweiligen SIMD-Instruction sets\footnote{Instruction Set - Befehlssatz (eines Prozessors) - (Unter)menge der vom Prozessor unterstützten Maschinencode-Befehle} unterstützen.

Es gibt zwar Ansätze, erst zur Laufzeit einen speziell auf die vorhandene Plattform abgestimmten Code zu benutzen, allerdings sind diese Ansätze je nach Zahl und Diversität der zu unterstützenden Plattformen nur mit stark erhöhtem Zeit- und damit finanziellem Aufwand umzusetzen, sofern der Code manuell der jeweiligen Plattform angepasst wird. Diese Möglichkeit beschreibt unter anderem Fog in \cite{Fog2010}\footnote{Anmerkung: Fog behandelt nicht die Optimierung für spezielle Echtzeitbetriebsssyteme, die im medizinischen Bereich zum Einsatz kommen}. Dagegen besteht auch die Möglichkeit, die Optimierung des Quellcode von einem Compiler\footnote{Compiler - Programm, das menschenlesbaren Quellcode in maschinenlesbare Befehle umsetzt} vornehmen zu lassen. Zum Zeitpunkt des Verfassens dieser Arbeit ist die Compilertechnologie jedoch noch nicht so weit fortgeschritten, dass die automatische Optimierung einen menschlichen Entwickler mit Erfahrung in diesem Bereich ersetzen könnte (siehe auch \cite{Fog2010}). Ausserdem bestehen hier starke Unterschiede zwichen den einzelnen Compilern - beispielsweise läuft vom Intel C++ Compiler generierter Maschinencode, der auf CPUs desselben Herstellers hochperformant läuft, oft nur langsam oder gar nicht auf Prozessoren des Konkurrenten AMD (vgl. \cite[Kapitel 2.5, Seite 10]{Fog2010}).
\subsubsection{Berechnung auf GPUs}\label{sssec:gpucalculation}
Da die Rechenleistung der Hauptprozessoren moderner Computer für viele der heutigen 3D-Anwendungen nicht mehr ausreicht, enthält ein Großteil der heutigen Computer Grafikhardware, die in der Lage ist, 3D-Anwendungen zu beschleunigen. Hierbei berechnet der Hauptprozessor die darzustellenden Daten und gibt sie an die Grafikhardware weiter, die diese Daten mithilfe der GPU\footnote{GPU - Graphics Processing Unit - Grafikprozessor} in ein zweidimensionales Bild umwandelt (rendert), das beispielsweise auf einem Monitor angezeigt werden kann.

Um der GPU mitzuteilen, welche Objekte wo im dreidimensionalen Koordinatensystem auf welche Art gerendert werden sollen, müssen Programme ein Grafik-API\footnote{API - Application Programming Interface - Programmierschnittstelle} wie OpenGL oder DirectX benutzen. Im konkreten Fall von VERTEBRA fiel die Entscheidung aufgrund der Plattformunabhängigkeit auf OpenGL.

Neuere GPUs können ausserdem so genannte Shader ausführen - kleine Programme, die für bestimmte Untereinheiten der zu visualisierenden Objekte ausgeführt werden. OpenGL stellt hierfür die Shaderprogrammiersprache GLSL\footnote{GLSL - [Open]Graphics Layer Shading Language - OpenGL-Shadersprache} zur Verfügung, die in \cite{Rost2006} für die OpenGL-Version 2.0 ausführlich beschrieben wird. Nach \cite[Seite 38-47]{Rost2006} können in dieser Sprachversion die folgenden Typen von Shadern unterschieden werden\footnote{Geometry-Shader sind im in \cite{Rost2006} benutzten Standard OpenGL 2.0 nicht enthalten und werden daher an dieser Stelle nicht aufgeführt}:
\begin{itemize}
 \item Vertex\footnote{Vertex - Ein einzelner Punkt im Raum, der einen Eckpunkt eines Polygons bzw. einen Punkt oder eines der Enden einer Linie darstellt. - Vgl. \cite[Seite 664]{Wright2000} bzw. \cite[Seite 685]{Rost2006}}-Shader
 \item Fragment\footnote{Fragment - Datensatz bestehend aus der Information, die nötig ist, um ein Pixel zu zeichnen\\Vgl. \cite[Seite 675]{Rost2006}}-Shader
\end{itemize}
Die Shader-Prozessoren (Untereinheiten der GPU, die die Shader ausführen), arbeiten massiv parallel, führen also das Shaderprogamm für eine große Zahl an Vertices bzw. Fragments gleichzeitig aus. Dies wird durch die spezielle Hardwarearchitektur von GPUs ermöglicht. Daraus resultiert ein großer Zuwachs an Geschwindigkeit, was speziell für Echtzeit-Tumorvisualisationssysteme wichtig ist, da die Operationen ständig über neuen Datensätzen berechnet werden müssen. Das in \vref{ssec:requirements} dargestellte Echzeitkriterium wäre nicht erfüllt, falls die Zeit, die benötigt wird, um die Berechnungen einschließlich Rendering auf einem Datensatz auszuführen, größer ist als die Zeitdifferenz zum Eintreffen des nächsten Datensatzes. Durch die massive Parallelisierung kann dieses Kriterium somit für größere Datensätze erfüllt werden.
Den Ansatz, Fragment-Shader für GPU-beschleunigtes Volumenrendering zu benutzen, verfolgen unter anderem Kruger und Westermann in \cite{Kruger2003}.

In den letzten Jahren tritt abgesehen von den Shadern vor allem das GPGPU\footnote{GPGPU - General Purpose Graphics Processing Unit}-Konzept in den Vordergrund, das die Möglichkeit bereitstellt, GPUs frei programmieren zu können, im Gegensatz zu Shadern aber nicht auf Grafikdatenmengen wie Vertices oder Framente sondern auf beliebigen Eingabedatensätzen ausgeführt wird. Wie auch bei Shadern kann die Anwendung von der massiven Parallelisierung profitieren. Auch für GPGPU-Programmierung müssen bestimmte APIs definiert werden, um der Applikation den nötigen Zugriff auf die Grafikhardware zu gewähren - \cite{Sanders2010} führt in das CUDA\footnote{CUDA - Compute Unified Device Architecture}-API des GPU-Herstellers NVIDIA ein, während \cite{Kirk2010} neben CUDA das herstellerunabhängige OpenCL\footnote{OpenCL - Open Computing Language} thematisiert. Marsalek et al. wenden schließlich das GPGPU-Konzept auf das Volumenrendering an und stellen ihre CUDA-basierte Implementation in \cite{Marsalek2008} vor.
\subsubsection{Berechnung auf FPGAs}\label{sssec:fpgacalculation}
Abgesehen von den bereits diskutierten Möglichkeiten ist mit so genannten FPGAs\footnote{FPGA - Field Programmable Gate Array} eine weitere Form der Hardwarebeschleunigung für die medizinische Visualisationstechnik vorhanden. FPGAs sind ICs\footnote{IC - Integrated Circuit - Integrierter Schaltkreis}, bei denen nach der Herstellung eine anwendungsspezifische Programmierung und Konfiguration möglich ist (\cite{Kibritev2009}, Kapitel 1.7.1, Seite 16). Daher sind die Produktionskosten für ein auf FPGAs basierendes Visualisationssystem wesentlich geringer als bei dedizierter Hardware, die für eine bestimmte Aufgabe gefertigt wurde und nicht nachträglich programmierbar ist. Wie bereits in Kapitel \vref{ssec:swhwcomparison} diskutiert stellt Bruckner in \cite{Bruckner2004} Nachteile von hardwarebasiertem Rendering gegenüber softwarebasierten Darstellungen in Bezug auf große volumetrische Datensätze dar. FPGAs erlauben, wie Leeser et al. in \cite{Leeser2005} mithilfe einer Implementation des Parallel-Beam Backprojection-Algorithmus zeigen, eine performante Implementation dieser Softwarealgorithmen. In \cite{Thomas2009} findet sich ein Vergleich die Performanz von CPU-, GPU- und FPGA-basierten Systemen anhand von PRNGs\footnote{PRNG - Pseudo-random number generator - Pseudozufallszahlengenerator} - wie aus Tabelle 6 ersichlich liefert das im Experiment benutzt FPGA-basierte System bei zwei der drei dargestellen Verteilungen, die jeweils unterschiedliche Algorithmen benötigen bessere Resultate (also eine größere Zahl generierter Zufallszahlen pro Zeiteinheit) als die anderen getesteten Plattformen.
\subsubsection{Berechnung auf Spezialhardware}\label{sssec:specialhardwarecalculation}
Neben den dargestellten Visualisationsmethoden gibt es durchaus Ansätze, die für die Visualisation nötigen Berechnungen auf spezialisierter Hardware auszuführen. Aufgrund des geringen Umfangs dieser Arbeit soll an dieser Stelle lediglich ein Überblick über die bereits bestehenden Hardwareplattformen gegeben werden. Diese Zusammenstellung basiert auf \cite[Kapitel 2.5.5, Seite 14]{Bruckner2004}.
\begin{itemize}
 \item Günter Knittel beschreibt in \cite{Knittel1995} mit VOGUE eine skalierbare Architektur für Volumenrendering
 \item VIRIM ist eine massiv-parallele, echtzeitfähige Volumenrenderingarchitektur, die in \cite{Guenther1995} beschrieben wird
 \item In \cite{Meissner2002} beschreiben Meißner et al. VIZARD II, eine interaktive und rekonfigurierbare Volumenrenderingarchitektur
 \item Eine kostenoptimierte, echtzeitfähige Architektur namens EM-Cube beschreiben Osborne et al. in \cite{Osborne1997}
 \item EM-Cube dient zudem als Basis für das kommerziell verfügbare VolumePro board, das in \cite{Pfister1999} beschrieben wird (vgl. \cite[Kapitel 2.2.5, Seite 14]{Bruckner2004})
\end{itemize}
Insbesondere bei \cite{Knittel1995}, \cite{Guenther1995} sowie \cite{Osborne1997} ist zu beachten, dass das Publikationsdatum sehr lange zurückliegt und daher unter Umständen nicht ausreichend mit aktueller Hardware zusammenarbeiten - beispielsweise könnte die Auflösung und Geschwindigkeit der heutigen Tomographen für die echtzeitfähigen Systeme ein Problem darstellen. Das kommerziell verfügbare VolumePro-Board aus \cite{Pfister1999} ist jedoch laut \cite[Kapitel 2.2.5, Seite 14]{Bruckner2004} fähig, einen Datensatz mit einer Auflösung von 512 in allen drei Raumdimensionen mit einer Geschwindigkeit von 30 FPS\footnote{FPS - Frames per second - Bilder pro Sekunde} zu rendern.
\subsubsection{Surface Rendering}\label{sssec:surfacerendering}
Die in dieser Arbeit behandelten Methoden beschränken sich auf das Volume Rendering (\glqq Volumenrendern\grqq\footnote{Anmerkung: Die Begriffe Volumenrendern und Volumenrendering werden in dieser Arbeit synonym verwendet}), d.h. die Daten werden unter Beachtung der räumlichen Information gerendert. Als Alternative bietet sich das so genannte Surface Rendering (`Oberflächenrendern`) an, bei dem durch mathematische Verfahren Oberflächen im Datensatz gesucht werden, die dann als zusammenhängende Fläche gerendert werden. 

Kuszyk et al. stellen in \cite{Kuszyk1996} die Nachteile des Surface Renderings gegenüber dem Volume Rendering dar. Als Beispiel für einen Nachteil des Surface Rendering wird dargestellt, dass Läsionen unter Knochen verborgen werden während Volume Rendering-Algorithmen diese korrekt darstellen (Quelle: \cite{Kuszyk1996}, Abstract). Da die Publikation jedoch schon 1996 veröffentlicht wurde, gelten die Resultate unter Umständen für die heutigen Algorithmen und hochauflösenden Tomographen. Eine aktuellere Darstellung liefern Udupa et al. in \cite{Udupa2009}. Die Autoren kommen zu dem Schluss, dass Surface Rendering-Algorithmen im Bereich der Informationsdarstellung einen kleinen Vorteil gegenüber volumenbasierten Algorithmen haben und außerdem durch den geringeren Bedarf an Rechenzeit und Speicherplatz überlegen sind. Auch \cite{Bruckner2004} thematisiert den Vergleich von Oberflächen- und Volumenrendering, kommt aber im Gegensatz zur vorgenannten Publikation zum Schluss, dass der Mehraufwand an Rechenzeit und Speicher die Mehrinformation wert, die im gerenderten Bild angezeigt wird - tatsächlich würde beim Rendern der Oberflächen eine Dimension verloren gehen, da das Innere von Objekten verborgen bleibt (Quelle: \cite[Seite 2f.]{Bruckner2004}).

\section{Augmented Reality - Zukunft von Visualisationssystemen?}\label{sec:augmentedreality}
In den letzten Jahren wird neben den herkömmlichen Geräten zu Darstellung der Informationen medizinischer Informationssysteme (z.B. Bildschirme) intensiv an der so genannten `Augmented Reality` geforscht. Dieser Begriff, der sich mit 'Erweiterte Realität' (Quelle: \cite[Seite 1]{Toe2010}) übersetzen lässt, beschreibt laut \cite{Suthau2002DE} (Seite 1; Englische Publikation: \cite{Suthau2002}) das Konzept, reale Bilder mit zusätzlichen Informationen zu ergänzen.

\subsection{Displays für AR-Applikationen}
In \cite[Kapitel 2.2, Seite 21]{Toe2010} werden zwei grundsätzliche Methoden unterschieden, die Kombination von realen und virtuellen Daten in visuellen Ausgabegeräten (Displays) umzusetzen:
\begin{itemize}
 \item \textbf{Optical See-Through Displays}: Diese Art von Displays, ermöglicht den \glqq direkten Blick auf die umgebende Welt\grqq\footnoteremember{f:Toe2010-S21}{Zitiert aus \cite[Kapitel 2.2, Seite 21]{Toe2010}}. Technisch kann dieses Konzept beispielsweise durch einen halbdurchlässigen Spiegel, der Combiner genannt wird, realisiert werden. Dadurch bleibt die \glqq direkte Sicht auf die Umgebung\grqq\footnoterecall{f:Toe2010-S21} erhalten und die Darstellungsqualität der realen Informationen wird nicht merklich verringert\footnote{Anmerkung: Der Anteil des Lichtes von aussen, der durch den halbdurchlässigen Spiegel das Auge nicht erreicht, ist üblicherweise vernachlässigbar klein}. Problematisch ist hierbei die je nach Geschwindigkeit des Systems verschieden große Verzögerung der virtuellen Komponente gegenüber dem realen Bild, die je nach Verarbeitung der Daten durch die Applikation unterschiedlich viel Zeit in Anspruch nehmen kann. Im Englischen wird diese Verzögerung mit \textit{lag} bezeichnet. Zur reinen Datenverarbeitung kommt hier noch hinzu, dass Position und Ausrichtung derjenigen Person, aus deren Sicht die Daten dargestellt werden sollen, von Sensoren erfasst und in Koordinaten und Winkel umgerechnet werden müssen, um dem Teil der Applikation, die die Visualisationsdaten berechnet, den zu rendern Blickwinkel sowie die Position des Betrachters mitteilen zu können (vgl. \cite[Kapitel 2.2, Seite 21f.]{Toe2010}). Eine zentrale Anforderung dieser Arbeit an die vorgestellten Konzepte ist, diesen \textit{lag} gering zu halten - optimalerweise unter der Wahrnehmbarkeitsschwelle. Technisch bedingt ist diese Verzögerung jedoch immer vorhanden.
 
 \item es
\end{itemize}


\section{Existierende Visualisationssysteme} \label{ssec:existingtvss}

\appendix \label{appendixstart}
\section{Anleitung zur Übersetzung von VERTEBRA}
Um den Quellcode von VERTEBRA in Maschinencode zu übersetzen, werden die folgenden Hilfsprogramme bzw. Bibliotheken benötigt:
\begin{itemize}
 \item C++-Compiler kompatibel zu ISO/IEC C++ 2003
 \item Qt Software Development Toolkit (SDK): minimal Version 4.7.0 = Qt SDK 2009.05.1
 \item DCMTK 3.5.4
\end{itemize}

Das Qt SDK kann von \url{http://qt.nokia.com} bezogen werden; die DCMTK-Bibliothek, die zum einlesen von DICOM-Daten benutzt wird, wird vom OFFIS e.v. (Oldenburger Forschungs- und Entwicklungsinstitut für Informatik, \url{http://offis.de}) auf \url{http://www.dcmtk.org/dcmtk.php.de} zu Verfügung gestellt.

Das Programm wurde mit der folgenden Konfiguration erfolgreich getestet (siehe auch Kapitel \vref{apdx:testplatform}):
\begin{itemize}
 \item C++-Compiler: GNU Compiler Collection \textit{gcc (Ubuntu/Linaro 4.4.4-14ubuntu5) 4.4.5}
 \item Qt SDK: 4.7.0 = Qt SDK 2009.05.1
\end{itemize}

\section{Testplattform}\label{apdx:testplatform}
Die in dieser Arbeit vorgestellten Geschwindigkeitsmessungen wurden auf der folgenden Plattform durchgeführt:
\begin{itemize}
  \item Dell Inspiron 530
  \item CPU: Intel\textsuperscript{\textregistered} Core\texttrademark 2 Duo E8300; 2.83GHz Taktfrequenz
  \item Betriebssystem: KUbuntu 10.10 x86\_64; Kernel 2.6.35-22-generic x86\_64
  \item Grafikhardware: NVidia\textsuperscript{\textregistered} GeForce 9400 GT, PCI Express x16\\
	Treiber 260.19.06 (Konfiguration: High Performance)
\end{itemize}
\newpage
\section{Verzeichnisse}
%\nocite{*}
\listoffigures
\renewcommand\refname{Literatur- und Quellenverzeichnis}
\bibliographystyle{alphadin}
\bibliography{visualization}
\clearpage
\section{Selbstständigkeitserklärung}
Hiermit erkläre ich, dass ich die vorliegende Arbeit in allen Teilen selbstständig verfasst habe und keine anderen als die angegebenen Quellen und Hilfsmittel (einschließlich Onlinequellen und elektronischer Medien) benutzt habe.
\vfill
\begin{center}
\underline{\hspace{10cm}}\vspace{1cm}
\end{center}
\begin{center}
Uli Köhler
\end{center}
\vfill
\end{document}
